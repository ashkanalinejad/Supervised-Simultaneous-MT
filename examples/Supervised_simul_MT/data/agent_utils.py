
import torch


def pad_fixed_sequence(seq, padding=1, seq_len=7):
    pad_length = seq_len - len(seq)
    padded_sequence = seq if pad_length == 0 else torch.cat((torch.tensor([padding]*pad_length,
                                                                          device=seq.device), seq))
    return padded_sequence


def generate_incremental_net_input(hypos, num_src=7, src_pad=1, trg_pad=1):
    # bsz x src_len x feat_len
    # 'action_seq -1' is because the first action will not be generated by the Agent
    max_action_len = max( [len(hypo['action_seq']) for hypo in hypos] )
    final_input = torch.ones(len(hypos), max_action_len-1, num_src+1,
                             dtype=torch.long,
                             device=hypos[0]['src_tokens'].device)
    for i, hypo in enumerate(hypos):
        sub_input = torch.ones(len(hypo['action_seq'])-1, num_src+1)
        for j in range(1, len(hypo['action_seq'])):
            # num read and write at previous time step
            num_write = sum(hypo['action_seq'][:j])
            num_read = len(hypo['action_seq'][:j]) - num_write

            src_tokens = pad_fixed_sequence(hypo['src_tokens'][num_read-num_src:num_read] if num_read >= num_src
                                            else hypo['src_tokens'][:num_read], padding=src_pad, seq_len=num_src)

            # The last write is EOS. We just need to continue to read more source words.
            # if num_write == sum(hypo['action_seq'][:]):
            #     num_write = num_write-1

            # The last read is EOS token. So it's the same as the lsat trg tokens
            if num_read == len(hypo['action_seq'][:]) - sum(hypo['action_seq'][:]):
                num_read = num_read-1

            # If the number of generated tokens less than the token we are looking for, then we just send
            # the padding and we expect the Agent generate read action for that time step.
            if num_write >= len(hypo['subsets'][num_read-1]['tokens']):
                trg_tokens = trg_pad
            else:
                trg_tokens = hypo['subsets'][num_read-1]['tokens'][num_write]
            input_elements = torch.cat((src_tokens.type(torch.LongTensor),
                                        torch.tensor(
                                            [trg_tokens],
                                            device=hypos[0]['src_tokens'].device
                                        ).type(torch.LongTensor)))
            sub_input[j-1] = input_elements
        final_input[i][:sub_input.shape[0]] = sub_input
    return final_input


def generate_incremental_net_input_2(hypos):
    # bsz x src_len x feat_len
    bsz = len(hypos)
    encoder_embed_dim = hypos[0]['encoder_out'].shape[1]
    decoder_embed_dim = hypos[0]['decoder_out'].shape[1]
    action_lens = [len(hypo['action_seq']) for hypo in hypos]

    # "+1" for attention weight
    feat_len = encoder_embed_dim + decoder_embed_dim + 1

    # 'action_lens -1' is because the first action will not be generated by the Agent
    final_input = torch.zeros(
        bsz, max(action_lens)-1, feat_len,
        dtype=torch.float,
        device=hypos[0]['src_tokens'].device
    )

    for i, hypo in enumerate(hypos):
        sub_input = torch.zeros(len(hypo['action_seq'])-1, feat_len,
                                device=hypos[0]['src_tokens'].device)
        for j in range(1, len(hypo['action_seq'])):
            # num read and write at previous time step
            num_write = sum(hypo['action_seq'][:j])
            num_read = len(hypo['action_seq'][:j]) - num_write

            # The last write is EOS. We just need to continue to read more source words.
            # if num_write == sum(hypo['action_seq'][:]):
            #     num_write = num_write-1

            # The last read is EOS token. So it's the same as the last trg token
            if num_read == len(hypo['action_seq'][:]) - sum(hypo['action_seq'][:]):
                num_read = num_read-1

            src_embedding = hypo['subsets'][num_read-1]['encoder_out'][num_read-1]
            # If the number of generated tokens are less than the token we are looking for, then we just send
            # the padding and we expect the Agent generate read action for that time step.
            if num_write >= hypo['subsets'][num_read-1]['decoder_out'].shape[0]:
                trg_embedding = torch.zeros(decoder_embed_dim)
                attention = 0
            else:
                trg_embedding = hypo['subsets'][num_read-1]['decoder_out'][num_write]
                attention = torch.mean(hypo['subsets'][num_read-1]['attention'][:, num_write])

            sub_input[j-1][:encoder_embed_dim] = src_embedding
            sub_input[j-1][encoder_embed_dim:feat_len-1] = trg_embedding
            sub_input[j-1][-1] = attention
        final_input[i][:sub_input.shape[0]] = sub_input[:].detach().clone()
    return final_input


def prepare_input(hypos, net_input, sample, agt_dict):
    agt_pad = agt_dict.pad_index
    sample['net_input']['src_tokens'] = net_input
    # The first read in the action sequence will not be generated by the Agent
    sample['net_input']['src_lengths'] = torch.tensor([len(hypo['action_seq'][1:]) for hypo in hypos], dtype=torch.long,
                                                      device=sample['net_input']['src_tokens'].device)

    sample['target'] = torch.empty(sample['net_input']['src_tokens'].shape[0],
                                   sample['net_input']['src_tokens'].shape[1], dtype=torch.long,
                                   device=sample['net_input']['src_tokens'].device).fill_(agt_pad)
    sample['net_input']['prev_output_tokens'] = torch.empty(sample['net_input']['src_tokens'].shape[0],
                                                            sample['net_input']['src_tokens'].shape[1],
                                                            dtype=torch.long,
                                                            device=sample['net_input']['src_tokens'].device
                                                            ).fill_(agt_pad)
    for i, hypo in enumerate(hypos):
        encoded_action = agt_dict.encode_line(" ".join(str(elem) for elem in hypo['action_seq']), append_eos=False)
        sample['target'][i][:len(hypo['action_seq'][1:])] = encoded_action[1:]
        sample['net_input']['prev_output_tokens'][i][:len(hypo['action_seq'][:-1])] = encoded_action[:-1]
    return sample


def prepare_simultaneous_input(hypos, sample, task):
    agt_dict = task.agent_dictionary
    if task.args.arch in ["agent_lstm", "agent_lstm_big", "agent_lstm_0", "agent_lstm_0_big"]:
        net_input = generate_incremental_net_input(
            hypos, num_src=1,
            src_pad=task.source_dictionary.pad_index,
            trg_pad=task.target_dictionary.pad_index
        )
        return prepare_input(hypos, net_input, sample, agt_dict)
    else:
        net_input = generate_incremental_net_input_2(hypos)
        return prepare_input(hypos, net_input, sample, agt_dict)


def modify_preprocessed_input(sample, task):
    if task.args.arch.startswith("agent_lstm_5"):
        num_prev_tokens = 3   # How many previous tokens should we send in each time
        pad_index = task.agent_dictionary.pad_index

        padded_sample = torch.empty(
            sample['action_seq'].shape[0], sample['action_seq'].shape[1]+num_prev_tokens-1
        ).fill_(pad_index)
        prev_token = torch.empty(sample['action_seq'].shape[0], sample['action_seq'].shape[1]-1, num_prev_tokens)

        padded_sample[:, num_prev_tokens-1:] = sample['action_seq']
        for i in range(num_prev_tokens):
            prev_token[:, :, i] = padded_sample[:, i:i-num_prev_tokens]
    else:
        prev_token = sample['action_seq'][:, :-1]
    net_input = {
        'src_tokens': torch.cat((sample['net_input']['src_tokens'].unsqueeze(2),
                                 sample['target'].unsqueeze(2)), dim=2),
        'src_lengths': sample['net_input']['src_lengths'],
        'prev_output_tokens': prev_token.type(torch.LongTensor)
    }
    new_sample = {
        'id': sample['id'],
        'nsentences': sample['nsentences'],
        'ntokens': sample['ntokens'],
        'net_input': net_input,
        'target': sample['action_seq'][:, 1:].contiguous()
    }
    return new_sample


def infer_input_features(hypos, previous_actions, all_features=True):
    bsz = len(hypos)
    pad = 1
    device = hypos[0][0]['tokens'].device
    if all_features:
        encoder_embed_dim = hypos[0][0]['encoder_out'].shape[1]
        decoder_embed_dim = hypos[0][0]['decoder_out'].shape[1]
        feat_len = 1 + encoder_embed_dim + decoder_embed_dim
    else:
        feat_len = 2

    num_writes = torch.sum(torch.eq(previous_actions, 5), dim=1)
    num_reads = torch.sum(torch.eq(previous_actions, 4), dim=1)

    final_features = torch.zeros(bsz, feat_len, dtype=torch.float, device=device)
    src_tokens = torch.zeros(bsz, dtype=torch.int, device=device)
    trg_tokens = torch.zeros(bsz, dtype=torch.int, device=device)

    for i, hypo in enumerate(hypos):
        num_read = int(num_reads[i])
        num_write = int(num_writes[i])
        send_padding = True if num_write > 1 and num_write >= len(hypo[num_read - 1]['tokens']) else False

        # We will use src and trg tokens for checking stopping criteria in the Agent.
        src_tokens[i] = hypo[-1]['src_tokens'][num_read - 1]
        trg_tokens[i] = hypo[num_read-1]['tokens'][num_write] if not send_padding else pad

        if all_features:
            src_embedding = hypo[num_read - 1]['encoder_out'][num_read - 1]
            trg_embedding = hypo[num_read - 1]['decoder_out'][num_write] \
                if not send_padding else torch.zeros(decoder_embed_dim)
            attention = torch.mean(hypo[num_read - 1]['attention'][:, num_write]) \
                if not send_padding else 0
            final_features[i][:encoder_embed_dim] = src_embedding
            final_features[i][encoder_embed_dim:feat_len-1] = trg_embedding
            final_features[i][-1] = attention
        else:
            final_features[i] = torch.cat((torch.tensor([src_tokens[i]], device=device).type(torch.LongTensor),
                                           torch.tensor([trg_tokens[i]], device=device).type(torch.LongTensor)))
    final_dict = {
        'src_tokens': src_tokens,
        'trg_tokens': trg_tokens,
        'input_features': final_features
    }
    return final_dict
